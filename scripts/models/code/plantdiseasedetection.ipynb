{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# import libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import MobileNet, ResNet50, VGG19, VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:24:00.590459Z","iopub.execute_input":"2023-11-07T21:24:00.590778Z","iopub.status.idle":"2023-11-07T21:24:36.402120Z","shell.execute_reply.started":"2023-11-07T21:24:00.590752Z","shell.execute_reply":"2023-11-07T21:24:36.401064Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"D1107 21:24:30.558598949    1886 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD1107 21:24:30.558620120    1886 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD1107 21:24:30.558623628    1886 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD1107 21:24:30.558626126    1886 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD1107 21:24:30.558628515    1886 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD1107 21:24:30.558630715    1886 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD1107 21:24:30.558637170    1886 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD1107 21:24:30.558639734    1886 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD1107 21:24:30.558642099    1886 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD1107 21:24:30.558644563    1886 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD1107 21:24:30.558647038    1886 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD1107 21:24:30.558649323    1886 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD1107 21:24:30.558651444    1886 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD1107 21:24:30.558653608    1886 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI1107 21:24:30.558871331    1886 ev_epoll1_linux.cc:122]               grpc epoll fd: 64\nD1107 21:24:30.558883363    1886 ev_posix.cc:144]                      Using polling engine: epoll1\nD1107 21:24:30.558958285    1886 dns_resolver_ares.cc:822]             Using ares dns resolver\nD1107 21:24:30.559428245    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1107 21:24:30.559440086    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1107 21:24:30.559443969    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1107 21:24:30.559447118    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1107 21:24:30.559450212    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1107 21:24:30.559453093    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD1107 21:24:30.559461156    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1107 21:24:30.559481360    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1107 21:24:30.559512601    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1107 21:24:30.559529610    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1107 21:24:30.559533078    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1107 21:24:30.559536516    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1107 21:24:30.559543815    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD1107 21:24:30.559547318    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1107 21:24:30.559550390    1886 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1107 21:24:30.559553445    1886 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI1107 21:24:30.562886470    1886 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI1107 21:24:30.577155974    1975 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1107 21:24:30.582590769    1975 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2023-11-07T21:24:30.582575681+00:00\", grpc_status:2}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Setup TPU","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:24:36.403733Z","iopub.execute_input":"2023-11-07T21:24:36.404208Z","iopub.status.idle":"2023-11-07T21:24:44.385248Z","shell.execute_reply.started":"2023-11-07T21:24:36.404180Z","shell.execute_reply":"2023-11-07T21:24:44.384473Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Running on TPU  \nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Setup Dataset","metadata":{}},{"cell_type":"code","source":"#Define the directory where your dataset is stored\ndataset_directory = '/kaggle/input/plant-disease-expert/Image Data base/Image Data base'\n\n# Get the list of class folders in the dataset directory\nclass_folders = [folder for folder in os.listdir(dataset_directory) if os.path.isdir(os.path.join(dataset_directory, folder))]\n\n# Initialize empty lists to store file paths for training and test sets\ntrain_file_paths = []\ntest_file_paths = []\n\n# Loop through each class folder and split the images into training and test sets\nfor class_folder in class_folders:\n    class_directory = os.path.join(dataset_directory, class_folder)\n\n    # Get the list of file paths for images in the current class folder\n    class_file_paths = [os.path.join(class_directory, filename) for filename in os.listdir(class_directory) if filename.endswith('.jpg')]\n\n    # Split the class data into training and test sets\n    class_train_paths, class_test_paths = train_test_split(class_file_paths, test_size=0.05, random_state=42)\n\n    # Add the split paths to the overall lists\n    train_file_paths.extend(class_train_paths)\n    test_file_paths.extend(class_test_paths)\n\n# Define the directories for storing training and test images\ntrain_directory = '/kaggle/working/train/'\ntest_directory = '/kaggle/working/test/'\n\n# Move training images to the train directory\nfor train_path in train_file_paths:\n    filename = os.path.basename(train_path)\n    class_folder = os.path.basename(os.path.dirname(train_path))\n    target_path = os.path.join(train_directory, class_folder, filename)\n    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n    shutil.copy(train_path, target_path)\n\n# Move test images to the test directory\nfor test_path in test_file_paths:\n    filename = os.path.basename(test_path)\n    class_folder = os.path.basename(os.path.dirname(test_path))\n    target_path = os.path.join(test_directory, class_folder, filename)\n    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n    shutil.copy(test_path, target_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:24:44.386161Z","iopub.execute_input":"2023-11-07T21:24:44.386387Z","iopub.status.idle":"2023-11-07T21:50:34.973116Z","shell.execute_reply.started":"2023-11-07T21:24:44.386366Z","shell.execute_reply":"2023-11-07T21:50:34.971827Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#  Resize the dataset","metadata":{}},{"cell_type":"code","source":"target_size = (224, 224) # Change this to the desired size for your model input\n\ndef check_image_validity(image_path):\n    try:\n        with Image.open(image_path) as img:\n            img.verify()\n    except (IOError, SyntaxError) as e:\n        print(f\"Invalid image found at {image_path}. Error: {e}\")\n        return False\n    return True\n\n# Loop through each class folder in the dataset\nfor class_folder in os.listdir(train_directory):\n    class_folder_path = os.path.join(train_directory, class_folder)\n    \n    # Loop through each image in the class folder\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith('.jpg'): # Assuming your images have the .jpg extension\n            # Check if the image is valid\n            image_path = os.path.join(class_folder_path, filename)\n            if check_image_validity(image_path):\n                # Open the image using PIL\n                image = Image.open(image_path)\n                im = image.convert('RGB')\n                \n                # Resize the image\n                resized_image = im.resize(target_size, Image.Resampling.LANCZOS)\n                \n                # Save the resized image, overwrite the original image if needed\n                resized_image.save(image_path)\n                \nfor class_folder in os.listdir(test_directory):\n    class_folder_path = os.path.join(train_directory, class_folder)\n    \n    # Loop through each image in the class folder\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith('.jpg'): # Assuming your images have the .jpg extension\n            # Check if the image is valid\n            image_path = os.path.join(class_folder_path, filename)\n            if check_image_validity(image_path):\n                # Open the image using PIL\n                image = Image.open(image_path)\n                im = image.convert('RGB')\n                \n                # Resize the image\n                resized_image = im.resize(target_size, Image.Resampling.LANCZOS)\n                \n                # Save the resized image, overwrite the original image if needed\n                resized_image.save(image_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:50:34.975946Z","iopub.execute_input":"2023-11-07T21:50:34.976278Z","iopub.status.idle":"2023-11-07T22:06:18.571667Z","shell.execute_reply.started":"2023-11-07T21:50:34.976250Z","shell.execute_reply":"2023-11-07T22:06:18.570297Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Define Hyperparameters","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64\nIMG_SIZE = (224, 224)\nNUM_CLASSES = 58\nEPOCHS = 5\nLR = 0.0009","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:18.573005Z","iopub.execute_input":"2023-11-07T22:06:18.573311Z","iopub.status.idle":"2023-11-07T22:06:18.577969Z","shell.execute_reply.started":"2023-11-07T22:06:18.573285Z","shell.execute_reply":"2023-11-07T22:06:18.577079Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data augmentation and preprocessing","metadata":{}},{"cell_type":"code","source":"train_directory = '/kaggle/working/train/'\ntest_directory = '/kaggle/working/test/'\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.05\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_directory,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training'\n)\n\nval_generator = train_datagen.flow_from_directory(\n    directory=train_directory,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:18.579137Z","iopub.execute_input":"2023-11-07T22:06:18.579410Z","iopub.status.idle":"2023-11-07T22:06:25.246080Z","shell.execute_reply.started":"2023-11-07T22:06:18.579389Z","shell.execute_reply":"2023-11-07T22:06:25.244758Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 180204 images belonging to 58 classes.\nFound 9456 images belonging to 58 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"\ndef create_mobilenet():\n    with strategy.scope():\n        base_model = MobileNet(weights = None, include_top=False, input_shape=(224, 224, 3))\n        model = tf.keras.Sequential([\n            base_model,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n        ])\n        model.summary()\n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n        return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:25.247426Z","iopub.execute_input":"2023-11-07T22:06:25.247735Z","iopub.status.idle":"2023-11-07T22:06:25.254325Z","shell.execute_reply.started":"2023-11-07T22:06:25.247708Z","shell.execute_reply":"2023-11-07T22:06:25.253244Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_vgg16net():\n    with strategy.scope():\n        base_model = VGG16(weights = None, include_top=False, input_shape=(224, 224, 3))\n        model = tf.keras.Sequential([\n            base_model,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n        ])\n        model.summary()\n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n        return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:25.255510Z","iopub.execute_input":"2023-11-07T22:06:25.255781Z","iopub.status.idle":"2023-11-07T22:06:25.265887Z","shell.execute_reply.started":"2023-11-07T22:06:25.255757Z","shell.execute_reply":"2023-11-07T22:06:25.265081Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def create_vgg19net():\n    with strategy.scope():\n        base_model = VGG19(weights = None, include_top=False, input_shape=(224, 224, 3))\n        model = tf.keras.Sequential([\n            base_model,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n        ])\n        model.summary()\n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n        return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:25.266860Z","iopub.execute_input":"2023-11-07T22:06:25.267132Z","iopub.status.idle":"2023-11-07T22:06:25.278405Z","shell.execute_reply.started":"2023-11-07T22:06:25.267108Z","shell.execute_reply":"2023-11-07T22:06:25.277463Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def create_resnet():\n    with strategy.scope():\n        base_model = ResNet50(weights = None, include_top=False, input_shape=(224, 224, 3))\n        model = tf.keras.Sequential([\n            base_model,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n        ])\n        model.summary()\n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n        return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:25.280915Z","iopub.execute_input":"2023-11-07T22:06:25.281167Z","iopub.status.idle":"2023-11-07T22:06:25.288092Z","shell.execute_reply.started":"2023-11-07T22:06:25.281146Z","shell.execute_reply":"2023-11-07T22:06:25.287223Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Define the list of architectures to compare","metadata":{}},{"cell_type":"code","source":"architectures = ['MobileNet', 'ResNet50', 'VGG19', 'VGG16']\nhistories = []\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:25.289088Z","iopub.execute_input":"2023-11-07T22:06:25.289364Z","iopub.status.idle":"2023-11-07T22:06:25.297489Z","shell.execute_reply.started":"2023-11-07T22:06:25.289343Z","shell.execute_reply":"2023-11-07T22:06:25.296589Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Loop through each architecture and train the model","metadata":{}},{"cell_type":"code","source":"for architecture in architectures:\n    print(f'Training {architecture}...')\n    # Create a new model within the strategy scope\n    if architecture == 'MobileNet':\n        model = create_mobilenet()\n    elif architecture == 'VGG16':\n        model = create_vgg16net()\n    elif architecture == 'VGG19':\n        model = create_vgg19net()\n    elif architecture == 'ResNet50':\n        model = create_resnet()\n    \n    # Train the model using TPU\n    history = model.fit(\n        train_datagen.flow_from_directory(\n            directory=train_directory,\n            target_size=IMG_SIZE,\n            batch_size=BATCH_SIZE,\n            class_mode='categorical',\n            subset='training'\n        ),\n        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n        validation_data=train_datagen.flow_from_directory(\n            directory=train_directory,\n            target_size=IMG_SIZE,\n            batch_size=BATCH_SIZE,\n            class_mode='categorical',\n            subset='validation'\n        ),\n        validation_steps=val_generator.samples // BATCH_SIZE,\n        epochs=EPOCHS\n    )\n    histories.append((architecture, history))\n    # Save the trained model\n    model.save(f'{architecture}_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-07T22:06:25.298566Z","iopub.execute_input":"2023-11-07T22:06:25.298828Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training MobileNet...\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n nal)                                                            \n                                                                 \n global_average_pooling2d (G  (None, 1024)             0         \n lobalAveragePooling2D)                                          \n                                                                 \n dense (Dense)               (None, 58)                59450     \n                                                                 \n=================================================================\nTotal params: 3,288,314\nTrainable params: 3,266,426\nNon-trainable params: 21,888\n_________________________________________________________________\nFound 180204 images belonging to 58 classes.\nFound 9456 images belonging to 58 classes.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-11-07 22:06:48.925364: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-11-07 22:06:49.322691: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"2815/2815 [==============================] - ETA: 0s - loss: 0.8664 - accuracy: 0.7454","output_type":"stream"},{"name":"stderr","text":"2023-11-07 22:40:21.576678: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-11-07 22:40:21.756256: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"2815/2815 [==============================] - 2128s 748ms/step - loss: 0.8664 - accuracy: 0.7454 - val_loss: 1.2155 - val_accuracy: 0.6840\nEpoch 2/5\n2815/2815 [==============================] - 2096s 745ms/step - loss: 0.2733 - accuracy: 0.9126 - val_loss: 0.2854 - val_accuracy: 0.9221\nEpoch 3/5\n2815/2815 [==============================] - 2058s 731ms/step - loss: 0.1811 - accuracy: 0.9421 - val_loss: 0.2154 - val_accuracy: 0.9360\nEpoch 4/5\n2815/2815 [==============================] - 2074s 737ms/step - loss: 0.1361 - accuracy: 0.9554 - val_loss: 0.1759 - val_accuracy: 0.9456\nEpoch 5/5\n2815/2815 [==============================] - 2097s 745ms/step - loss: 0.1103 - accuracy: 0.9638 - val_loss: 0.3506 - val_accuracy: 0.8989\nTraining ResNet50...\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n                                                                 \n global_average_pooling2d_1   (None, 2048)             0         \n (GlobalAveragePooling2D)                                        \n                                                                 \n dense_1 (Dense)             (None, 58)                118842    \n                                                                 \n=================================================================\nTotal params: 23,706,554\nTrainable params: 23,653,434\nNon-trainable params: 53,120\n_________________________________________________________________\nFound 180204 images belonging to 58 classes.\nFound 9456 images belonging to 58 classes.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-11-08 01:01:34.703457: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-11-08 01:01:35.488029: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"2815/2815 [==============================] - ETA: 0s - loss: 0.7971 - accuracy: 0.7717","output_type":"stream"},{"name":"stderr","text":"2023-11-08 01:35:32.303406: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-11-08 01:35:32.551386: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"2815/2815 [==============================] - 2169s 750ms/step - loss: 0.7971 - accuracy: 0.7717 - val_loss: 1.9615 - val_accuracy: 0.7150\nEpoch 2/5\n2815/2815 [==============================] - 2085s 741ms/step - loss: 0.2581 - accuracy: 0.9181 - val_loss: 0.5619 - val_accuracy: 0.8406\nEpoch 3/5\n2815/2815 [==============================] - 2102s 747ms/step - loss: 0.1690 - accuracy: 0.9450 - val_loss: 0.4812 - val_accuracy: 0.8616\nEpoch 4/5\n2815/2815 [==============================] - 2079s 739ms/step - loss: 0.1249 - accuracy: 0.9593 - val_loss: 0.3903 - val_accuracy: 0.8866\nEpoch 5/5\n2815/2815 [==============================] - 2064s 733ms/step - loss: 0.0967 - accuracy: 0.9679 - val_loss: 0.1971 - val_accuracy: 0.9518\nTraining VGG19...\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n                                                                 \n global_average_pooling2d_2   (None, 512)              0         \n (GlobalAveragePooling2D)                                        \n                                                                 \n dense_2 (Dense)             (None, 58)                29754     \n                                                                 \n=================================================================\nTotal params: 20,054,138\nTrainable params: 20,054,138\nNon-trainable params: 0\n_________________________________________________________________\nFound 180204 images belonging to 58 classes.\nFound 9456 images belonging to 58 classes.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-11-08 03:56:29.028761: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-11-08 03:56:29.242319: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"2815/2815 [==============================] - ETA: 0s - loss: 2.1691 - accuracy: 0.5391","output_type":"stream"},{"name":"stderr","text":"2023-11-08 04:29:42.165861: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-11-08 04:29:42.302848: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"2815/2815 [==============================] - 2105s 741ms/step - loss: 2.1691 - accuracy: 0.5391 - val_loss: 0.8050 - val_accuracy: 0.7536\nEpoch 2/5\n1600/2815 [================>.............] - ETA: 14:26 - loss: 0.6353 - accuracy: 0.8013","output_type":"stream"}]},{"cell_type":"markdown","source":"# Plot the training and validation loss","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nfor name, history in histories:\n    plt.plot(history.history['loss'], label=f'{name} - Training Loss')\n    plt.plot(history.history['val_loss'], label=f'{name} - Validation Loss')\n\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss Comparison')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot the training and validation accuracy","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nfor name, history in histories:\n    plt.plot(history.history['accuracy'], label=f'{name} - Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label=f'{name} - Validation Accuracy')\n\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy Comparison')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test each model","metadata":{}},{"cell_type":"markdown","source":"## Load the testing data and preprocess it\n","metadata":{}},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale without augmentation for testing data\n\ntest_generator = test_datagen.flow_from_list(\n    test_file_paths,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the saved models","metadata":{}},{"cell_type":"code","source":"models = []\nfor name in architectures:\n    model = tf.keras.models.load_model(f'/kaggle/working/{name}_model.h5')\n    models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate each model on the testing set","metadata":{}},{"cell_type":"code","source":"for name, model in zip(architecture_names, models):\n    print(f'Evaluating {name} model...')\n    loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n    print(f'{name} Model - Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}